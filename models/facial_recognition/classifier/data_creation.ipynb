{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-04-07T16:14:41.540763Z","iopub.status.busy":"2024-04-07T16:14:41.540427Z","iopub.status.idle":"2024-04-07T16:15:23.325432Z","shell.execute_reply":"2024-04-07T16:15:23.323881Z","shell.execute_reply.started":"2024-04-07T16:14:41.540734Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow_hub==0.16.1\n","  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: numpy>=1.12.0 in /Users/munmun/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_hub==0.16.1) (1.19.5)\n","Collecting protobuf>=3.19.6 (from tensorflow_hub==0.16.1)\n","  Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n","Collecting tf-keras>=2.14.1 (from tensorflow_hub==0.16.1)\n","  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n","INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n","  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n","Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n","Downloading protobuf-5.26.1-cp37-abi3-macosx_10_9_universal2.whl (404 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.0/404.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tf-keras, protobuf, tensorflow_hub\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.4.1 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n","tensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.9.0 which is incompatible.\n","tensorflow 2.4.1 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-5.26.1 tensorflow_hub-0.16.1 tf-keras-2.15.0\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.0.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow_text==2.15.0 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow_text==2.15.0\u001b[0m\u001b[31m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.0.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n","\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.15 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.15\u001b[0m\u001b[31m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m22.0.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install tensorflow_hub==0.16.1\n","%pip install tensorflow_text==2.15.0\n","%pip install tensorflow==2.15"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-07T16:21:01.884836Z","iopub.status.busy":"2024-04-07T16:21:01.884420Z","iopub.status.idle":"2024-04-07T16:21:14.026294Z","shell.execute_reply":"2024-04-07T16:21:14.024985Z","shell.execute_reply.started":"2024-04-07T16:21:01.884798Z"},"trusted":true},"outputs":[{"ename":"ImportError","evalue":"\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"/Users/munmun/opt/anaconda3/bin/python\"\n  * The NumPy version is: \"1.20.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so, 0x0002): tried: '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (no such file), '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/__init__.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multiarray\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/multiarray.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m overrides\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _multiarray_umath\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/overrides.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multiarray_umath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n","\u001b[0;31mImportError\u001b[0m: dlopen(/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so, 0x0002): tried: '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (no such file), '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This Python 3 environment comes with many helpful analytics libraries installed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# For example, here's several helpful packages to load\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# linear algebra\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \u001b[38;5;66;03m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/__init__.py:145\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Allow distributors to run custom init code\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m core\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n","File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/__init__.py:48\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;124mIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m0\u001b[39m], sys\u001b[38;5;241m.\u001b[39mversion_info[\u001b[38;5;241m1\u001b[39m], sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[1;32m     47\u001b[0m         __version__, exc)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m envkey \u001b[38;5;129;01min\u001b[39;00m env_added:\n","\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.8 from \"/Users/munmun/opt/anaconda3/bin/python\"\n  * The NumPy version is: \"1.20.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: dlopen(/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so, 0x0002): tried: '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (no such file), '/Users/munmun/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_multiarray_umath.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","%pip install keras-core\n","from keras_nlp.models import BertPreprocessor, BertBackbone\n","import tensorflow_hub as hub\n","import tensorflow_text as text\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:21:14.031626Z","iopub.status.busy":"2024-04-07T16:21:14.029144Z","iopub.status.idle":"2024-04-07T16:21:14.046862Z","shell.execute_reply":"2024-04-07T16:21:14.045438Z","shell.execute_reply.started":"2024-04-07T16:21:14.031583Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(r\"/kaggle/input/person-recognition-dataset/data.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:21:14.049645Z","iopub.status.busy":"2024-04-07T16:21:14.048849Z","iopub.status.idle":"2024-04-07T16:21:14.062418Z","shell.execute_reply":"2024-04-07T16:21:14.060979Z","shell.execute_reply.started":"2024-04-07T16:21:14.049603Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>prompt</th>\n","      <th>model</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Counted the individuals present?</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Who's close by, ready to jump into the discuss...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Can you spot anyone you haven't met?</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Any sightings of Eliana in sight?</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Are there any unfamiliar faces in sight?</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                             prompt  model\n","0           0                   Counted the individuals present?      2\n","1           1  Who's close by, ready to jump into the discuss...      0\n","2           2               Can you spot anyone you haven't met?      3\n","3           3                  Any sightings of Eliana in sight?      1\n","4           4           Are there any unfamiliar faces in sight?      3"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:21:14.066128Z","iopub.status.busy":"2024-04-07T16:21:14.065048Z","iopub.status.idle":"2024-04-07T16:21:15.054937Z","shell.execute_reply":"2024-04-07T16:21:15.053952Z","shell.execute_reply.started":"2024-04-07T16:21:14.066092Z"},"trusted":true},"outputs":[],"source":["# I forgot to make x train, y train\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(df['prompt'],df['model'], stratify=df['model'])\n","\n","# Because we're not doing binary classification\n","y_train = pd.get_dummies(y_train).astype(int).to_numpy()\n","y_test = pd.get_dummies(y_test).astype(int).to_numpy()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:21:15.057004Z","iopub.status.busy":"2024-04-07T16:21:15.056394Z","iopub.status.idle":"2024-04-07T16:21:17.251089Z","shell.execute_reply":"2024-04-07T16:21:17.249970Z","shell.execute_reply.started":"2024-04-07T16:21:15.056971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Attaching 'tokenizer.json' from model 'keras/bert/keras/bert_base_en_uncased/2' to your Kaggle notebook...\n","Attaching 'tokenizer.json' from model 'keras/bert/keras/bert_base_en_uncased/2' to your Kaggle notebook...\n","Attaching 'assets/tokenizer/vocabulary.txt' from model 'keras/bert/keras/bert_base_en_uncased/2' to your Kaggle notebook...\n"]}],"source":["# Tokenize so we can train on a TPU\n","preprocessor = BertPreprocessor.from_preset(\"bert_base_en_uncased\",trainable=True)\n","X_train_inputs = preprocessor(X_train)\n","X_test_inputs = preprocessor(X_test)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:28:39.266380Z","iopub.status.busy":"2024-04-07T16:28:39.265130Z","iopub.status.idle":"2024-04-07T16:28:39.308693Z","shell.execute_reply":"2024-04-07T16:28:39.307303Z","shell.execute_reply.started":"2024-04-07T16:28:39.266334Z"},"trusted":true},"outputs":[{"ename":"AttributeError","evalue":"'dict' object has no attribute 'shape'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_train_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"]}],"source":["X_train_inputs"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:22:50.835041Z","iopub.status.busy":"2024-04-07T16:22:50.834389Z","iopub.status.idle":"2024-04-07T16:22:57.095221Z","shell.execute_reply":"2024-04-07T16:22:57.094140Z","shell.execute_reply.started":"2024-04-07T16:22:50.835004Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Attaching 'tokenizer.json' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n","Attaching 'tokenizer.json' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n","Attaching 'assets/tokenizer/vocabulary.txt' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n","Attaching 'config.json' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n","Attaching 'config.json' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n","Attaching 'model.weights.h5' from model 'keras/bert/keras/bert_small_en_uncased/2' to your Kaggle notebook...\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"functional_5\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bert_preprocessor_4 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertPreprocessor</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │                   │\n","│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bert_backbone       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">28,763,648</span> │ bert_preprocesso… │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BertBackbone</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)] │            │ bert_preprocesso… │\n","│                     │                   │            │ bert_preprocesso… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bert_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense-1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │ dropout-1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense-1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense-2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │ dropout-2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense-2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span> │ dropout-output[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n","│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ -                 │\n","│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bert_preprocessor_4 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n","│ (\u001b[38;5;33mBertPreprocessor\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │                   │\n","│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ bert_backbone       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),     │ \u001b[38;5;34m28,763,648\u001b[0m │ bert_preprocesso… │\n","│ (\u001b[38;5;33mBertBackbone\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m)] │            │ bert_preprocesso… │\n","│                     │                   │            │ bert_preprocesso… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bert_backbone[\u001b[38;5;34m0\u001b[0m]… │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense-1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m32,832\u001b[0m │ dropout-1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense-1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dense-2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │      \u001b[38;5;34m1,040\u001b[0m │ dropout-2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ dropout-output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense-2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n","│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n","├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n","│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │         \u001b[38;5;34m68\u001b[0m │ dropout-output[\u001b[38;5;34m0\u001b[0m… │\n","└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,797,588</span> (109.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,797,588\u001b[0m (109.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,797,588</span> (109.85 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,797,588\u001b[0m (109.85 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["None\n"]}],"source":["\n","# Use BERT\n","text_input = tf.keras.layers.Input(shape=(), dtype=tf.dict)\n","preprocessor = BertPreprocessor.from_preset(\"bert_small_en_uncased\",trainable=True)\n","encoder_inputs = preprocessor(text_input)\n","encoder = BertBackbone.from_preset(\"bert_small_en_uncased\")\n","outputs = encoder(encoder_inputs)\n","pooled_output = outputs[\"pooled_output\"]      # [batch_size, 768].\n","sequence_output = outputs[\"sequence_output\"]  # [batch_size, seq_length, 768].\n","\n","# Now use that for classification\n","# Neural network layers\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout-1\")(pooled_output)\n","l = tf.keras.layers.Dense(64, activation='relu', name=\"dense-1\")(l)\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout-2\")(l)\n","l = tf.keras.layers.Dense(16, activation='relu', name=\"dense-2\")(l)\n","l = tf.keras.layers.Dropout(0.1, name=\"dropout-output\")(l)\n","l = tf.keras.layers.Dense(4, activation='relu', name=\"output\")(l)\n","\n","\n","# Create the model\n","# Use inputs and outputs to construct a final model\n","model = tf.keras.Model(inputs=[text_input], outputs = [l])\n","METRICS = [\n","      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","      tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.Recall(name='recall')\n","]\n","\n","print(model.summary())\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=METRICS)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:22:58.947600Z","iopub.status.busy":"2024-04-07T16:22:58.947150Z","iopub.status.idle":"2024-04-07T16:22:58.953659Z","shell.execute_reply":"2024-04-07T16:22:58.952886Z","shell.execute_reply.started":"2024-04-07T16:22:58.947565Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(628, 4)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-07T16:22:59.971562Z","iopub.status.busy":"2024-04-07T16:22:59.970905Z","iopub.status.idle":"2024-04-07T16:26:46.651213Z","shell.execute_reply":"2024-04-07T16:26:46.649340Z","shell.execute_reply.started":"2024-04-07T16:22:59.971527Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/25\n","\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m2:33\u001b[0m 11s/step - accuracy: 0.5164 - loss: 8.1427 - precision: 0.2473 - recall: 0.4594"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_temp_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      2\u001b[0m earlystopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearlystopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint('my_temp_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n","earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n","\n","history = model.fit(\n","    X_train, y_train, \n","    validation_split=0.2, \n","    epochs=25,\n","    callbacks=[checkpoint, earlystopping],\n","    batch_size=16\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-07T16:20:57.063064Z","iopub.status.idle":"2024-04-07T16:20:57.063412Z","shell.execute_reply":"2024-04-07T16:20:57.063261Z","shell.execute_reply.started":"2024-04-07T16:20:57.063233Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Get training history\n","train_loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","train_acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","# Plot training and validation loss\n","plt.plot(train_loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","# Plot training and validation accuracy\n","plt.plot(train_acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T23:24:09.847442Z","iopub.status.busy":"2024-04-06T23:24:09.847076Z","iopub.status.idle":"2024-04-06T23:24:11.460674Z","shell.execute_reply":"2024-04-06T23:24:11.459769Z","shell.execute_reply.started":"2024-04-06T23:24:09.847414Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 1s 178ms/step - loss: 1.4284 - accuracy: 0.7500 - precision: 0.0000e+00 - recall: 0.0000e+00\n"]},{"data":{"text/plain":["[1.4284303188323975, 0.75, 0.0, 0.0]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Evaluate on test data\n","model.evaluate(x=X_test, y=y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-06T23:18:28.007423Z","iopub.status.idle":"2024-04-06T23:18:28.007884Z","shell.execute_reply":"2024-04-06T23:18:28.007706Z","shell.execute_reply.started":"2024-04-06T23:18:28.007688Z"},"trusted":true},"outputs":[],"source":["model.save(\"final_model.h5\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T23:35:28.027400Z","iopub.status.busy":"2024-04-06T23:35:28.027063Z","iopub.status.idle":"2024-04-06T23:35:29.498265Z","shell.execute_reply":"2024-04-06T23:35:29.496991Z","shell.execute_reply.started":"2024-04-06T23:35:28.027375Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 1s 161ms/step\n"]},{"ename":"NameError","evalue":"name 'y_preed' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 2\u001b[0m \u001b[43my_preed\u001b[49m\n","\u001b[0;31mNameError\u001b[0m: name 'y_preed' is not defined"]}],"source":["y_pred = model.predict(X_test)\n"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T23:39:42.677521Z","iopub.status.busy":"2024-04-06T23:39:42.676866Z","iopub.status.idle":"2024-04-06T23:39:42.691207Z","shell.execute_reply":"2024-04-06T23:39:42.690304Z","shell.execute_reply.started":"2024-04-06T23:39:42.677482Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"," 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n","[2 2 0 3 2 3 3 3 3 2 3 2 3 3 2 0 0 0 3 0 1 3 0 1 2 1 0 2 0 3 2 2 0 2 1 1 3\n"," 2 1 3 0 2 2 1 2 3 1 2 0 2 3 0 3 1 2 0 3 0 3 3 2 2 0 0 2 2 0 2 0 1 0 1 3 2\n"," 2 0 0 1 1 1 2 3 3 3 3 0 0 2 2 1 0 3 3 2 2 1 1 1 0 1 0 1 0 2 3 0 1 0 1 2 3\n"," 3 2 1 0 0 3 0 3 1 0 3 2 1 0 2 1 1 1 1 1 2 1 3 2 1 3 1 3 1 1 1 3 0 3 2 2 2\n"," 3 0 1 0 1 2 3 2 1 1 0 0 2 3 3 2 2 2 2 2 0 2 1 0 3 3 0 0 1 3 2 3 1 2 3 3 0\n"," 1 0 2 2 0 3 2 1 1 1 0 0 0 0 2 1 3 1 0 3 0 0 1 0 1]\n"]},{"data":{"text/plain":["array([[0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 0, 1, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 1, 0],\n","       [0, 1, 0, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0]])"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["print(np.argmax(y_pred,axis=1))\n","print(np.argmax(y_test, axis=1))\n","y_test"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T23:35:07.947607Z","iopub.status.busy":"2024-04-06T23:35:07.946813Z","iopub.status.idle":"2024-04-06T23:35:08.183364Z","shell.execute_reply":"2024-04-06T23:35:08.181982Z","shell.execute_reply.started":"2024-04-06T23:35:07.947575Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"Singleton array 10 cannot be considered a valid collection.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m y_test\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Create confusion matrix and normalizes it over predicted (columns)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Plot confusion matrix as heatmap\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:317\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[1;32m    233\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    234\u001b[0m ):\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:394\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:394\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:335\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[1;32m    337\u001b[0m         )\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n","\u001b[0;31mTypeError\u001b[0m: Singleton array 10 cannot be considered a valid collection."]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","y_prediction = np.argmax(y_pred, axis = 0)\n","y_test=np.argmax(y_test, axis=0)\n","#Create confusion matrix and normalizes it over predicted (columns)\n","result = confusion_matrix(y_test, y_prediction , normalize='pred')\n","\n","# Plot confusion matrix as heatmap\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', \n","            xticklabels=labels, yticklabels=labels)\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8162592,"datasetId":4746251,"sourceId":8048648,"sourceType":"datasetVersion"},{"databundleVersionId":4932971,"modelInstanceId":2180,"sourceId":2938,"sourceType":"modelInstanceVersion"},{"databundleVersionId":7429175,"modelInstanceId":4676,"sourceId":6055,"sourceType":"modelInstanceVersion"},{"databundleVersionId":7429181,"modelInstanceId":4678,"sourceId":6057,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
